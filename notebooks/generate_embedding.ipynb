{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = \"../data/cleaned_data/cleaned_data_train.csv\"\n",
    "data_test_path = \"../data/cleaned_data/cleaned_data_test.csv\"\n",
    "data_dev_path = \"../data/cleaned_data/cleaned_data_dev.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path):\n",
    "    # Load your dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initialize variables for storing sequences\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    sentence = []\n",
    "    label_seq = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        # Check for sentence end\n",
    "        if row['token'] != '.':  # Replace '.' with your sentence delimiter, if any\n",
    "            sentence.append(row['token'])\n",
    "            label_seq.append(row['label'])\n",
    "        else:\n",
    "            # Add the completed sentence and labels to the lists\n",
    "            sentences.append(sentence)\n",
    "            labels.append(label_seq)\n",
    "            sentence = []\n",
    "            label_seq = []\n",
    "\n",
    "    # Handle any leftover sequence (if the dataset doesn't end with a sentence delimiter)\n",
    "    if sentence and label_seq:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label_seq)\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels = prepare_data(data_train_path)\n",
    "test_sentences, test_labels = prepare_data(data_test_path)\n",
    "dev_sentences, dev_labels = prepare_data(data_dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 923)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'this',\n",
       " 'article',\n",
       " 'we',\n",
       " 'discuss',\n",
       " 'several',\n",
       " 'metrics',\n",
       " 'of',\n",
       " 'coherence',\n",
       " 'defined',\n",
       " 'using',\n",
       " 'centering',\n",
       " 'theory',\n",
       " 'and',\n",
       " 'investigate',\n",
       " 'the',\n",
       " 'usefulness',\n",
       " 'of',\n",
       " 'such',\n",
       " 'metrics',\n",
       " 'for',\n",
       " 'information',\n",
       " 'ordering',\n",
       " 'in',\n",
       " 'automatic',\n",
       " 'text',\n",
       " 'generation']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train_sentences, test_sentences, and dev_sentences\n",
    "all_sentences = train_sentences + test_sentences + dev_sentences\n",
    "all_labels = train_labels + test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1172, 1058)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_sentences, vector_size=300, window=5, min_count=2, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11733633e-02,  1.24633089e-01,  9.28443205e-03,  7.17265680e-02,\n",
       "       -5.76661527e-03, -1.38257161e-01,  1.06778659e-01,  3.03798378e-01,\n",
       "        1.09113166e-02, -1.83319277e-03, -2.17040032e-02, -1.34624526e-01,\n",
       "       -1.17992202e-03,  4.41281162e-02, -1.23243921e-01, -9.81178060e-02,\n",
       "        9.23287794e-02,  4.15359903e-03,  2.82037798e-02, -3.43210101e-02,\n",
       "       -4.59621474e-02, -4.29066159e-02,  1.24193765e-01,  4.04658280e-02,\n",
       "        1.09530270e-01, -2.78591886e-02, -1.37272507e-01,  4.18445915e-02,\n",
       "       -1.00793928e-01, -1.16419174e-01,  4.32174280e-02, -4.30817492e-02,\n",
       "        5.76726794e-02, -1.55678811e-02,  2.03437563e-02,  1.27075380e-02,\n",
       "        2.61044912e-02, -1.39524594e-01,  1.33019220e-02, -2.99425069e-02,\n",
       "       -6.23868667e-02,  5.37047759e-02,  3.11366003e-03, -1.00717045e-01,\n",
       "        4.57360446e-02,  1.40916333e-01,  1.42081897e-03,  4.22880091e-02,\n",
       "       -3.81673947e-02,  8.95741805e-02,  3.74806784e-02,  2.93084532e-02,\n",
       "       -1.04871035e-01,  2.27892008e-02, -3.40006724e-02,  1.40624538e-01,\n",
       "        7.82597214e-02, -2.04063654e-02,  4.26488370e-02, -1.75857043e-03,\n",
       "       -4.82940748e-02, -3.43369208e-02, -1.20446524e-02,  6.02142513e-02,\n",
       "       -8.02261697e-04,  8.22272971e-02, -3.81756062e-03,  6.63581565e-02,\n",
       "       -7.74686188e-02, -4.31437306e-02,  1.38841700e-02,  1.16667166e-01,\n",
       "        8.85414779e-02, -1.46478534e-01,  9.25864279e-03,  1.55053455e-02,\n",
       "       -7.77824074e-02,  1.42911468e-02, -3.33799422e-02,  8.04808065e-02,\n",
       "       -4.70467582e-02, -1.18901134e-01,  1.22568372e-03,  2.56489754e-01,\n",
       "        4.16431911e-02,  4.00401326e-03, -4.58267182e-02, -4.94495109e-02,\n",
       "        8.79115835e-02, -1.34289742e-03,  1.17362127e-01, -9.60451514e-02,\n",
       "        7.72409216e-02,  3.87755744e-02,  1.81926191e-01,  1.38813347e-01,\n",
       "        9.20757502e-02, -3.20188440e-02, -8.33474994e-02,  8.96978378e-02,\n",
       "       -2.98074204e-02,  2.00328659e-02,  6.60303831e-02,  6.74195066e-02,\n",
       "        3.16927657e-02, -7.87300989e-02,  3.63225527e-02,  5.59749752e-02,\n",
       "       -1.47744238e-01, -3.55142110e-04, -1.21873945e-01, -8.14451873e-02,\n",
       "        1.42946783e-05,  9.46404934e-02,  4.21057679e-02,  5.67979664e-02,\n",
       "        1.01522254e-02, -1.16744302e-02,  1.17217258e-01, -1.76103801e-01,\n",
       "        8.07978660e-02,  4.55092974e-02,  8.44605863e-02, -3.29951793e-02,\n",
       "       -8.99042934e-02,  5.08422926e-02,  6.57937909e-03, -1.28570229e-01,\n",
       "       -9.49212909e-03,  8.33863541e-02,  3.77763957e-02,  1.46463260e-01,\n",
       "        2.91443914e-02, -1.20115064e-01,  5.60498238e-02,  7.69004524e-02,\n",
       "       -3.77544202e-02, -8.95175040e-02, -1.27116710e-01, -1.51740804e-01,\n",
       "        1.19243294e-01, -1.33577049e-01, -1.05544357e-02,  8.74052420e-02,\n",
       "        7.87931010e-02, -8.87888744e-02, -1.78291872e-01, -4.58650514e-02,\n",
       "        3.16179022e-02, -4.86070700e-02,  3.50996368e-02, -1.71642005e-01,\n",
       "       -5.50758727e-02, -4.45192270e-02,  4.53690700e-02,  1.05659917e-01,\n",
       "       -8.61837864e-02, -6.59641400e-02, -4.62637730e-02,  1.30368337e-01,\n",
       "        8.84716772e-03,  1.21011689e-01, -1.03219919e-01,  1.32296816e-01,\n",
       "       -9.71818417e-02,  7.96996206e-02,  1.31893102e-02, -2.61492133e-02,\n",
       "        1.32227205e-02,  2.27159590e-01, -1.68563984e-02, -2.74565015e-02,\n",
       "        6.34201095e-02,  6.90133497e-02, -1.18902707e-02,  3.27520482e-02,\n",
       "        5.45752756e-02, -1.48584202e-01,  2.21996848e-02, -2.45861299e-02,\n",
       "       -6.26975074e-02,  5.60566783e-02, -6.59943819e-02, -8.97536799e-02,\n",
       "       -7.26113990e-02,  4.39701490e-02,  1.71854526e-01,  1.33598447e-01,\n",
       "        7.26740882e-02, -1.21998891e-01,  5.50885964e-03, -2.12615244e-02,\n",
       "       -1.35554180e-01,  1.18573811e-02,  2.69801021e-02, -1.09922439e-01,\n",
       "        7.90051371e-03, -1.10866837e-01,  3.84941585e-02,  2.02209633e-02,\n",
       "       -9.13501084e-02,  3.44867781e-02, -5.30711785e-02, -7.80932754e-02,\n",
       "       -3.27397548e-02, -2.91113332e-02,  3.54362675e-03,  3.89542691e-02,\n",
       "       -9.65099316e-03, -4.52376232e-02,  2.47332212e-02, -1.03584841e-01,\n",
       "       -8.01856741e-02, -7.41191134e-02,  1.33843973e-01, -9.05201733e-02,\n",
       "       -2.29832884e-02, -2.29074255e-01, -1.41995981e-01, -1.17199153e-01,\n",
       "        2.60919426e-02,  3.03926487e-02, -8.89855698e-02, -1.69435337e-01,\n",
       "       -1.38370723e-01, -8.88071582e-02,  2.43580565e-02, -2.42070742e-02,\n",
       "       -1.12676285e-01,  5.07920161e-02,  1.08528443e-01, -4.65672202e-02,\n",
       "       -8.53874460e-02,  6.85156435e-02, -9.37920362e-02, -2.38062721e-03,\n",
       "        2.56394353e-02,  1.71124283e-02,  5.53232543e-02, -2.12858573e-01,\n",
       "        7.40950709e-05, -5.92405833e-02, -3.53135429e-02,  5.80850523e-03,\n",
       "        7.93027356e-02, -7.52723292e-02, -1.12200053e-02,  3.07929255e-02,\n",
       "       -6.66159689e-02,  5.44849150e-02,  9.73840728e-02,  2.23372076e-02,\n",
       "        4.79903221e-02,  4.78940643e-03, -1.61910892e-01, -6.60705566e-02,\n",
       "        2.18035460e-01,  2.13319659e-02, -1.26942366e-01, -1.14963703e-01,\n",
       "        4.42664176e-02,  5.94513752e-02,  3.61909978e-02, -1.86786607e-01,\n",
       "       -1.13404937e-01,  6.03630282e-02,  7.29363635e-02,  9.17121470e-02,\n",
       "       -1.56898826e-01,  2.39119269e-02, -1.09747022e-01,  2.75075156e-02,\n",
       "       -4.24466375e-03, -3.13645341e-02,  1.30215183e-01,  6.14628643e-02,\n",
       "        8.79852176e-02,  4.67557386e-02, -1.41461745e-01, -3.39284614e-02,\n",
       "        9.27530676e-02, -8.72809906e-03, -5.99296726e-02,  9.27683413e-02,\n",
       "        2.15973109e-02,  2.68333638e-03, -1.51473597e-01,  5.78732304e-02,\n",
       "        9.28440783e-03,  9.43112522e-02,  3.03676538e-02,  1.56738192e-01,\n",
       "        1.43686131e-01,  1.51065644e-02,  1.51689455e-01,  1.70426458e-01,\n",
       "        5.72861321e-02, -4.24354039e-02,  1.37409955e-01, -4.08113636e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['NLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('../models/trained_models/word2vec_model_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = Word2Vec.load('../models/trained_models/word2vec_model_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('for', 0.9997607469558716),\n",
       " ('and', 0.9997566938400269),\n",
       " ('than', 0.9997555017471313),\n",
       " (',', 0.9997542500495911),\n",
       " ('using', 0.9997527599334717),\n",
       " ('(', 0.999751627445221),\n",
       " ('the', 0.9997514486312866),\n",
       " (')', 0.9997497797012329),\n",
       " ('has', 0.9997488260269165),\n",
       " ('have', 0.9997475147247314)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a FastText model with the given parameters\n",
    "fast_text_model = FastText(sentences=all_sentences, vector_size=300, window=5, min_count=2, sg=0, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machines', 0.9999983906745911),\n",
       " ('Machine', 0.9999964237213135),\n",
       " ('matching', 0.9999943971633911),\n",
       " ('approaching', 0.9999943375587463),\n",
       " ('achieving', 0.999994158744812),\n",
       " ('improving', 0.9999939203262329),\n",
       " ('contrasting', 0.9999939203262329),\n",
       " ('modeling', 0.9999939203262329),\n",
       " ('comparing', 0.9999939203262329),\n",
       " ('mapping', 0.9999938607215881)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_model.wv.most_similar(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model.save(\"../models/trained_models/fasttext_model_embedding.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from each sentence\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = [remove_stopwords(sentence) for sentence in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(cleaned_sentences, vector_size=300, window=5, min_count=2, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 0.9996338486671448),\n",
       " ('models', 0.999614953994751),\n",
       " ('-', 0.9995870590209961),\n",
       " ('learning', 0.9995536208152771),\n",
       " ('data', 0.9995476603507996),\n",
       " ('translation', 0.9995428919792175),\n",
       " ('used', 0.999542772769928),\n",
       " ('model', 0.9995414614677429),\n",
       " ('information', 0.9995402097702026),\n",
       " ('two', 0.9995371699333191)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.save('../models/trained_models/word2vec_model_embedding2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a FastText model with the given parameters\n",
    "fast_text_model = FastText(sentences=cleaned_sentences, vector_size=300, window=5, min_count=2, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machines', 0.9999980926513672),\n",
       " ('Machine', 0.9999961853027344),\n",
       " ('approaching', 0.9999948143959045),\n",
       " ('matching', 0.9999947547912598),\n",
       " ('Representations', 0.9999945759773254),\n",
       " ('contrasting', 0.9999945759773254),\n",
       " ('achieving', 0.9999945163726807),\n",
       " ('prominent', 0.9999944567680359),\n",
       " ('translations', 0.9999944567680359),\n",
       " ('representations', 0.9999944567680359)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_model.wv.most_similar(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving the model: 600000000 requested and 0 written\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"../models/trained_models\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "\t# Save the FastText model\n",
    "\tfast_text_model.save(\"../models/trained_models/fasttext_model_embedding2.h5\")\n",
    "\tprint(\"Model saved successfully.\")\n",
    "except OSError as e:\n",
    "\tprint(f\"Error saving the model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
